{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8222d6ZMz8Nm"
      },
      "source": [
        "# A practical guide to multilingual large language  model (RoBERTa) classification\n",
        "\n",
        "This step-by-step tutorial provides a gentle introduction to customizing (fine-tuning) a pre-trained multilingual language model (RoBERTa) for text classification tasks. It demonstrates how to use the model's existing knowledge to classify text accurately, even with a small set of labeled examples. It takes input as text documents and their corresponding labels for training, validating and testing. It covers using specialized models for English, German, and French, but employs XLM-RoBERTa, which can be used for over 100 languages.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "This tutorial answers the following questions:\n",
        "\n",
        "- What exactly is text-classification?\n",
        "- What is a pre-trained language model?\n",
        "- What even is fine-tuning?\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "\n",
        "-\tWork with large language models for text classification (RoBERTa)\n",
        "-\tCustomize (fine-tunine) a large language model for a text classification task in any language (100+ languages supported)\n",
        "-\tEmploy low-resource learning (with only few hundred examples) using the SAM optimizer\n",
        "\n",
        "## Target Audience\n",
        "\n",
        "This tutorial is aimed at an intermediate level. You should have basic knowledge of large language models and of Python programming.\n",
        "\n",
        "## Duration\n",
        "\n",
        "About half a work-day.\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "- Training and then using a text classifier for special text data, for example to detect sentiment of specific texts, hatefulness of social media posts or something completely different like whether a text contains mentions of fruits or not.\n",
        "\n",
        "## Environment Setup\n",
        "\n",
        "Use this tutorial preferably in an environment with GPU access like Colab.\n",
        "\n",
        "Run the cells below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KuYVJkLn_b0"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet transformers pandas\n",
        "!wget --quiet https://raw.githubusercontent.com/davda54/sam/main/sam.py  # download the SAM optimizer code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZpvTl_jHGEi"
      },
      "outputs": [],
      "source": [
        "# Import packages used in the tutorial\n",
        "\n",
        "import pandas\n",
        "from sam import SAM\n",
        "import shutil\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUCEaj7BDygM"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "What exactly is **text-classification**?\n",
        "\n",
        "In text-classification we try to assign a property to a text.\n",
        "\n",
        "For example we are interested in classifying texts that are about fruits. We could easily find a dictionary with all fruits (e.g.: 'Apple', 'Banana', 'Pear' etc.). Everytime we recognize a word from this dictionary in a text we know this text is about fruits, right? However, this might not be true all the time. For example \"Apple designed the new pencil pro.\" is not about the fruit 'Apple' although we would recognize it as such with our dictionary approach. So the context of the word might be helpful (more on this later). Furthermore, dictionaries work only for the language in the dictionary. However, we aim for multilingual approaches in this tutorial and will thus replace dictionaries with AI methods later in this tutorial.\n",
        "\n",
        "Classification is obviously transferable to more than just fruits. People try to classify the sentiment of a text, the stance towards an entity expressed in a text, the topic of a text, the expressed emotion in a text, and many many more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCBUwjg5DwTW"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "We here focus on text-classification in its purest form, i.e., have as data points single texts, each of which is assigned a single label (or class) that our classifier has to predict (as opposed to multi-label classification, in which a text can be assigned none up to all available labels, see the \"Defining the Classification Task\" section). We use the following format for this tutorial:\n",
        "\n",
        "```python\n",
        "{\n",
        "  'Text': [\"text1\", \"text2\", \"...\", \"textN\"]\n",
        "  'Labels': [\"label-of-text1\", \"label-of-text2\", \"...\", \"label-of-textN\"]\n",
        "}\n",
        "```\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "{\n",
        "  'Text': ['Yesterday i ate an apple.', 'Yesterday I crashed my Apple.'],\n",
        "  'Labels': ['about_fruit', 'not_about_fruit']\n",
        "}\n",
        "```\n",
        "\n",
        "As in most classification settings, we separate our data into three parts:\n",
        "\n",
        "- train. Contains the data on which classifiers are based (\"training data\")\n",
        "- val. Contains the data based on which we select a classifier among the available ones (\"validation data\")\n",
        "- test. Contains the data to give us an estimate of the performance of the selected classifier (\"test data\")\n",
        "\n",
        "These different datasets should all be independent from each other, so that (1) we select the classifier that generalizes best to the validation data it does not know from the training data and (2) we get a solid performance estimate of the classifier in the wild from the test data (that was neither used to train nor to validate/select the classifier).\n",
        "\n",
        "We take an old Twitter [Bag Brands Sentiment Dataset](https://doi.org/10.5281/zenodo.7679325) as data. Feel free to use your own data instead."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://zenodo.org/records/7679325/files/bag_brand_sentiment_dataset.xlsx\n",
        "\n",
        "data = pandas.read_excel('bag_brand_sentiment_dataset.xlsx')\n",
        "data.head()  # have a look at the first 5 texts"
      ],
      "metadata": {
        "id": "514Du_SGpdj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first column contains the text, whereas the `sentiment` column contains the label.\n",
        "\n",
        "We now transform it into our simple structure detailed above:"
      ],
      "metadata": {
        "id": "1q2ymRmNuilv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_all = {\n",
        "    \"Text\": data[0].tolist(),\n",
        "    \"Labels\": data[\"sentiment\"].tolist()\n",
        "}\n",
        "num_data_all = len(data_all[\"Text\"])\n",
        "\n",
        "# It is always good to check whether your data is \"balanced\", i.e., whether it\n",
        "# has a similar amount of data for each class:\n",
        "from collections import Counter\n",
        "print(\"Total:\", Counter(data_all[\"Labels\"]))\n",
        "\n",
        "# And split the data into three parts:\n",
        "split_target_size = int(num_data_all/3)\n",
        "train = {\n",
        "    \"Text\": data_all[\"Text\"][:(split_target_size)],\n",
        "    \"Labels\": data_all[\"Labels\"][:(split_target_size)]\n",
        "}\n",
        "print(\"Train:\", Counter(train[\"Labels\"]))\n",
        "val = {\n",
        "    \"Text\": data_all[\"Text\"][(split_target_size):(2*split_target_size)],\n",
        "    \"Labels\": data_all[\"Labels\"][(split_target_size):(2*split_target_size)]\n",
        "}\n",
        "print(\"Val:  \", Counter(val[\"Labels\"]))\n",
        "test = {\n",
        "    \"Text\": data_all[\"Text\"][(2*split_target_size):],\n",
        "    \"Labels\": data_all[\"Labels\"][(2*split_target_size):]\n",
        "}\n",
        "print(\"Test: \", Counter(test[\"Labels\"]))\n",
        "print()\n",
        "\n",
        "assert len(train['Text']) == len(train['Labels']), \"Number of texts does not match number of labels for train data!\"\n",
        "assert len(val['Text']) == len(val['Labels']), \"Number of texts does not match number of labels for val data!\"\n",
        "assert len(test['Text']) == len(test['Labels']), \"Number of texts does not match number of labels for test data!\"\n",
        "\n",
        "print(f\"The train data has {len(train['Text'])} texts and {len(train['Labels'])} labels,\")\n",
        "print(f\"the validation data {len(val['Text'])} texts and {len(val['Labels'])} labels\")\n",
        "print(f\"and the test data {len(test['Text'])} texts and {len(test['Labels'])} labels.\")\n",
        "print()\n",
        "\n",
        "print(\"First five training texts:\")\n",
        "for i in range(5):\n",
        "    print(f\"'{train['Text'][i]}', {train['Labels'][i]}\")"
      ],
      "metadata": {
        "id": "xEqGgh3EvOb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, to avoid that our model just learns to pick the most common label (as that is the most likely to be the case if is is unsure), we balance the training set by oversampling so that it contains the same number of examples for each label."
      ],
      "metadata": {
        "id": "zjzJ1jAgja1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "counts = Counter(train['Labels'])\n",
        "max_count = max(counts.values())\n",
        "for label, count in counts.items():\n",
        "    label_indices = [i for i, train_label in enumerate(train['Labels']) if train_label == label]\n",
        "    selected_indices = random.choices(label_indices, k=max_count - count)\n",
        "    train['Text'] += [train['Text'][i] for i in selected_indices]\n",
        "    train['Labels'] += [train['Labels'][i] for i in selected_indices]\n",
        "\n",
        "# now shuffle the data again\n",
        "indices = random.sample(range(len(train['Text'])), len(train['Text']))\n",
        "train['Text'] = [train['Text'][i] for i in indices]\n",
        "train['Labels'] = [train['Labels'][i] for i in indices]\n",
        "print(\"Train:\", Counter(train[\"Labels\"]))"
      ],
      "metadata": {
        "id": "GWLdqgQHkA-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WQ19YMNEAuK"
      },
      "source": [
        "Great, the data is ready!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BYdtu44Xrhp"
      },
      "source": [
        "## Selecting a Pre-Trained Language Model\n",
        "\n",
        "In which language is the text in the data written? Many language models are trained to understand a particular language. In case you need to process text of just one language, taking such a specialized model is often a good idea. However, also cross-language models exist, which were trained on many different language. We use a cross-language model here, but you can comment out one of the other lines to use a language-specific model instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHzEmeSnXq2w"
      },
      "outputs": [],
      "source": [
        "model_name = 'xlm-roberta-base'                        # for 100 languages\n",
        "# model_name = \"roberta-base\"                          # for English\n",
        "# model_name = \"benjamin/roberta-base-wechsel-german\"  # for German\n",
        "# model_name = \"camembert-base\"                        # for French"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq68uB4cbnKc"
      },
      "source": [
        "What is this ``model_name``? It relates to our second question:\n",
        "\n",
        "What is a **pre-trained language model**?\n",
        "\n",
        "A pre-trained language model has be trained to predict words in a text. Usually, single words are removed from a text to make kind of a cloze test. The model is trained to fill in the gap with the word that we removed. This process is done for millions of texts, making the model somewhat adapt at \"speaking\" the language(s). This is called pre-training, as it teaches the model a specific skill (e.g., language understanding) that is useful for many other skills (e.g., predicting the sentiment of a text).\n",
        "\n",
        "What even is **fine-tuning**?\n",
        "\n",
        "It means to take a pre-trained model and training it now on the actual task we want it to solve. Since the model already has useful skills (e.g., language understanding), we need less training data to transform it into an expert for the task. To highlight that this is a (relatively) small adjustment, this step is called \"fine-tuning\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pm-wgbhEarc"
      },
      "source": [
        "## Defining the Classification Task\n",
        "\n",
        "As said above, classification tasks can be separated into single-label and multi-label classification. This tutorial by default uses single-label classification, but it also contains the code for multi-label classification, in case that is what you need when you use your own data. Here is a more detailed distinction:\n",
        "\n",
        "1. Single-Label Classification\n",
        "\n",
        "  - Select one label from a list of possible labels.\n",
        "  - Example: Does this text have a *positive* or a *negative* sentiment?\n",
        "\n",
        "2. Multi-Label Classification\n",
        "  - Decide for each label from a list of possible labels whether it applies.\n",
        "  - Example: Is this text *positive*, *in formal language* and/or *easy to read*?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP2b9HkBY1Qc"
      },
      "outputs": [],
      "source": [
        "# Classify by 'single_label_classification' or 'multi_label_classification'?\n",
        "problem_type =  'single_label_classification'\n",
        "\n",
        "# Ensure the labels align with the selected classification type\n",
        "if problem_type == 'single_label_classification':\n",
        "    assert isinstance(train['Labels'][0], str), (\n",
        "        \"For 'single-label' tasks, labels should be strings (e.g., 'positive').\"\n",
        "    )\n",
        "elif problem_type == 'multi_label_classification':\n",
        "    assert isinstance(train['Labels'][0], list), (\n",
        "        \"For 'multi-label' tasks, labels should be a list \" \\\n",
        "        + \"(e.g., ['positive', 'easy-to-read']).\"\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Invalid classification type: {problem_type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is always advised to check your data behaves like you would expect it to:"
      ],
      "metadata": {
        "id": "Ov4cgrSKIqS3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6AKMt2JiLd7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_unique_labels(data):\n",
        "    \"\"\"\n",
        "    Returns the number of possible labels and the possible labels.\n",
        "    \"\"\"\n",
        "    def flatten_list(list_to_flatten):\n",
        "        return [x for xs in list_to_flatten for x in xs]\n",
        "\n",
        "    labels = data['Labels']\n",
        "    if problem_type == 'multi_label_classification':\n",
        "        labels = flatten_list(labels)\n",
        "\n",
        "    labels = set(labels)\n",
        "    return labels\n",
        "\n",
        "\n",
        "labels_train = get_unique_labels(train)\n",
        "labels_val = get_unique_labels(val)\n",
        "labels_test = get_unique_labels(test)\n",
        "\n",
        "assert labels_train == labels_val == labels_test, (\n",
        "    \"Train, val and test must contain the same labels, but the where\\n\"\n",
        "    f\"{labels_train},\\n{labels_val} and\\n{labels_test}, respectively\"\n",
        ")\n",
        "\n",
        "print(f\"Labels (same across train, val and test): {list(labels_train)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYAu-jSLtSBf"
      },
      "source": [
        "## Setting up the Model\n",
        "\n",
        "The next step is to load the model and tokenizer. The tokenizer translates text into a model-specific vocabulary (usually numbers) that the model can process efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGtsc2tGtQWi"
      },
      "outputs": [],
      "source": [
        "# The AI library uses integer numbers instead of strings for labels\n",
        "# We convert them into each other with these dictionaries\n",
        "id2label = {i: k for i, k in enumerate(labels_train)}  # id2label[0] == labels_train[0]\n",
        "label2id = {k: i for i, k in enumerate(labels_train)}  # label2id[labels_train[0]] == 0\n",
        "\n",
        "model_config = {'pretrained_model_name_or_path': model_name,\n",
        "                'num_labels': len(labels_train),\n",
        "                'problem_type': problem_type,\n",
        "                'id2label': id2label,\n",
        "                'label2id': label2id}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(**model_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLFf-h69n8Nn"
      },
      "source": [
        "Now we specify training-specific parameters. Do not worry if you are unsure about what to change if you use your own data. The preset values should work just fine for most cases.\n",
        "\n",
        "In general, when training a model, you provide it with some example data points (in your case, the training data). From this data, the model learns helpful patterns that explain the correlation between input and output.\n",
        "\n",
        "Key parameters of the training are:\n",
        "\n",
        "- **batch_size**: Determines how many examples we show to the model at a time before deducing how to improve classification.  \n",
        "- **learning_rate**: Controls how strongly the model commits to patterns it recognizes within each batch.  \n",
        "- **num_epoch**: Specifies how many times the model sees all the training data (e.g., 3 times).  \n",
        "- **warm_up_rate**: Indicates the portion of training during which the model makes smaller adjustments.\n",
        "- **device**: Refers to the hardware used for training. If you have a GPU (\"[cuda](https://en.wikipedia.org/wiki/CUDA) device\"), your training will be much faster.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWLgh6LRGNOE"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 3  # how often we go through the entire training dataset\n",
        "warm_up_rate = 0.1  # fraction of our training steps for warm-up scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w37QzRN_U41u"
      },
      "source": [
        "Next we create dataloaders to prepare the data for the model training. This involves to convert both the texts and the labels from string to integers: tokenization (texts to sequences of numbers) and label2id mapping (labels to numbers). Both are then used in the dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIP_Jj34oz9r"
      },
      "outputs": [],
      "source": [
        "# Convert text into the model vocabulary (tokenization)\n",
        "train_text = tokenizer([m for m in train['Text']], truncation=True, padding='longest', return_tensors='pt')\n",
        "val_text = tokenizer([m for m in val['Text']], truncation=True, padding='longest', return_tensors='pt')\n",
        "test_text = tokenizer([m for m in test['Text']], truncation=True, padding='longest', return_tensors='pt')\n",
        "\n",
        "# Convert label strings into label ids (using the label2id mapping)\n",
        "def map_labels(labels, mapping):\n",
        "    if isinstance(labels[0], list):  # multi-label classification\n",
        "        label_matrix = []\n",
        "        for text_labels in labels:  # text_labels: labels for one text\n",
        "            label_vector = torch.tensor([\n",
        "                # vector of 0s and 1s, the index encodes the label\n",
        "                1 if label in text_labels else 0 for label in mapping\n",
        "            ])\n",
        "            label_matrix.append(label_vector)\n",
        "        labels = torch.stack(label_matrix, dim=0)\n",
        "    return torch.tensor([mapping[label] for label in labels])\n",
        "\n",
        "train_y = map_labels(train['Labels'], label2id)\n",
        "val_y = map_labels(val['Labels'], label2id)\n",
        "test_y = map_labels(test['Labels'], label2id)\n",
        "\n",
        "# Get dataloaders for iteration over the data\n",
        "def generate_dataloader(text, y, batch_size, workers=1):\n",
        "    \"\"\"\n",
        "    Returns a dataloader with input_ids and attention_mask to process the text.\n",
        "    \"\"\"\n",
        "    attention_mask = text['attention_mask']\n",
        "    input_ids = text['input_ids']\n",
        "    dataset = list(zip(input_ids, attention_mask, y))\n",
        "    dataloader = DataLoader(\n",
        "        dataset, shuffle=True, batch_size=batch_size, num_workers=workers)\n",
        "    return dataloader\n",
        "\n",
        "train_dataloader = generate_dataloader(train_text, train_y, batch_size)\n",
        "val_dataloader = generate_dataloader(val_text, val_y, batch_size)\n",
        "test_dataloader = generate_dataloader(test_text, test_y, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELylkOMArO-h"
      },
      "source": [
        "The learning of patterns and adaptation of the model is achieved by the optimizer. In our case it is a special optimizer that keeps a model from optimizing too much to the training data-which often results in less generalization to new data. You can find the technical details in [the SAM optimizer repository](https://github.com/davda54/sam)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFuqFXajGfJ6"
      },
      "outputs": [],
      "source": [
        "optimizer = SAM(model.parameters(), torch.optim.Adam, lr=learning_rate, adaptive=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scheduler adapts the learning rate of the optimizer (by how much it adopts the model in a learning step) during the learning process. There are several different scheduling strategies, though typically they decrease the learning rate after some initial (\"warm up\") steps. The further one is in training, one typically assumes that only minor adoptions to the model are necessary to really hit the optimum."
      ],
      "metadata": {
        "id": "W1BRgRKM9zVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_steps = (len(train['Labels']) // batch_size) * num_epochs\n",
        "num_warmup_steps = int(num_training_steps * warm_up_rate)\n",
        "\n",
        "scheduler = transformers.get_cosine_schedule_with_warmup(\n",
        "    optimizer = optimizer,\n",
        "    num_warmup_steps = num_warmup_steps,\n",
        "    num_training_steps = num_training_steps,\n",
        "    last_epoch = -1\n",
        ")"
      ],
      "metadata": {
        "id": "uCI9gyCP9z-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start the training, let us check our available ressources and compare with the batch size (how much of the training data we load at once - if we have a small GPU only, larger batches might not fit into it at once)."
      ],
      "metadata": {
        "id": "In8FUQGL_RCO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUwFFftDV457"
      },
      "outputs": [],
      "source": [
        "# Memory and system check before training\n",
        "import psutil\n",
        "import gc\n",
        "import os\n",
        "\n",
        "# Set tokenizers parallelism to avoid fork warnings\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Check system memory\n",
        "memory = psutil.virtual_memory()\n",
        "print(f\"System Memory: {memory.total / 1024**3:.2f} GB total, {memory.available / 1024**3:.2f} GB available\")\n",
        "\n",
        "\n",
        "# Check GPU memory if available\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "if device != 'cpu':\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "    gpu_memory_allocated = torch.cuda.memory_allocated(0)\n",
        "    gpu_memory_reserved = torch.cuda.memory_reserved(0)\n",
        "\n",
        "    print(f\"GPU Memory: {gpu_memory / 1024**3:.2f} GB total\")\n",
        "    print(f\"GPU Memory Allocated: {gpu_memory_allocated / 1024**3:.2f} GB\")\n",
        "    print(f\"GPU Memory Reserved: {gpu_memory_reserved / 1024**3:.2f} GB\")\n",
        "\n",
        "    # Clear any existing GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"Device: {device}\")\n",
        "else:\n",
        "    print(\"No GPU available - using CPU\")\n",
        "\n",
        "# Check model size\n",
        "model_size = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model has {model_size:,} parameters\")\n",
        "\n",
        "# Recommend batch size based on available memory\n",
        "if device != 'cpu':\n",
        "    available_gpu_memory = gpu_memory - gpu_memory_reserved\n",
        "    if available_gpu_memory < 4 * 1024**3:  # Less than 4GB available\n",
        "        recommended_batch_size = 8\n",
        "    elif available_gpu_memory < 8 * 1024**3:  # Less than 8GB available\n",
        "        recommended_batch_size = 16\n",
        "    else:\n",
        "        recommended_batch_size = 32\n",
        "\n",
        "    print(f\"Recommended batch size: {recommended_batch_size}\")\n",
        "\n",
        "    if batch_size > recommended_batch_size:\n",
        "        print(f\"Warning: Current batch size ({batch_size}) may be too large. Consider reducing to {recommended_batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_hiMENYrwM0"
      },
      "source": [
        "## Fine-Tuning the Pre-Trained Model\n",
        "\n",
        "(\"Fine-tuning\" means to train an already pre-trained model to a specific task)\n",
        "\n",
        "Let's start the training process!  \n",
        "\n",
        "During fine-tuning, we show the training data to the model and adjust its parameters to optimize performance for the task. Here is what happens:\n",
        "\n",
        "- The model learns patterns in the data to perform the classification task.  \n",
        "- After each **epoch** (a complete pass through the training dataset), we test the model on the validation set to monitor progress.  \n",
        "- The best-performing model is saved during the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e35OhfF0JO52"
      },
      "outputs": [],
      "source": [
        "best_loss = float('inf')\n",
        "best_epoch = 0\n",
        "already_trained = 0\n",
        "best_model_path = ''\n",
        "should_delete = True\n",
        "\n",
        "# Move model to device\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs): # Repeat num_epochs times\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader): # Train the model on the batch\n",
        "        try:\n",
        "            input_ids, attention_mask, y = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "\n",
        "            # First forward pass\n",
        "            output = model(input_ids, attention_mask, labels=y)\n",
        "            loss = output.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # SAM optimizer first step\n",
        "            optimizer.first_step(zero_grad=True)\n",
        "\n",
        "            # Second forward pass (required by SAM)\n",
        "            output2 = model(input_ids, attention_mask, labels=y)\n",
        "            loss2 = output2.loss\n",
        "            loss2.backward()\n",
        "\n",
        "            # SAM optimizer second step\n",
        "            optimizer.second_step(zero_grad=True)\n",
        "\n",
        "            # Update learning rate AFTER optimizer steps\n",
        "            scheduler.step()\n",
        "\n",
        "            print(f\"Train: Epoch {epoch}, Train step {already_trained+batch_idx}, Loss {loss.item():.4f}, learning_rate {scheduler.get_last_lr()[0]:.2e}\", flush=True)\n",
        "\n",
        "            # Clear cache periodically to prevent memory buildup\n",
        "            if batch_idx % 5 == 0 and torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                print(f\"OOM Error at batch {batch_idx}. Trying to recover...\")\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "                # Try with smaller effective batch size\n",
        "                if batch_size > 8:\n",
        "                    batch_size = batch_size // 2\n",
        "                    print(f\"Reducing batch size to {batch_size}\")\n",
        "                    train_dataloader = generate_dataloader(train_text, train_y, batch_size)\n",
        "                    val_dataloader = generate_dataloader(val_text, val_y, batch_size)\n",
        "                    break\n",
        "                else:\n",
        "                    raise e\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    already_trained += batch_idx\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader): # Validate the current state of the model on the validation data\n",
        "            input_ids, attention_mask, y = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "            val_output = model(input_ids, attention_mask, labels=y)\n",
        "            val_loss.append(val_output.loss)\n",
        "\n",
        "    val_loss = torch.mean(torch.stack(val_loss))\n",
        "\n",
        "    print(f\"Validation: Epoch {epoch}, Train step {already_trained}, Loss {val_loss.item():.4f}, old best/epoch {str(best_loss)[1:6]}/{best_epoch}\", flush=True)\n",
        "\n",
        "    if val_loss < best_loss: # Save the model if the val_loss is the best loss we have seen so far\n",
        "        best_loss = val_loss.item()\n",
        "        best_epoch = epoch\n",
        "        if should_delete and best_model_path and os.path.exists(best_model_path):\n",
        "            shutil.rmtree(best_model_path)\n",
        "        best_model_path = f\"./my_model_epoch_{best_epoch}_val_loss_{str(val_loss.item())[1:6]}\"\n",
        "        model.save_pretrained(best_model_path, from_pt=True)\n",
        "\n",
        "        print(f\"**** END EPOCH {epoch} ****\")\n",
        "\n",
        "    # Clean up memory after each epoch\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(f\"**** FINISHED TRAINING FOR N={num_epochs} ****\")\n",
        "print(f\"BEST EPOCH: {best_epoch}\")\n",
        "print(f\"BEST LOSS: {best_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6IoeYsasTlt"
      },
      "source": [
        "The training is finished now we can load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlEDLy1qCONM"
      },
      "outputs": [],
      "source": [
        "best_model = AutoModelForSequenceClassification.from_pretrained(best_model_path).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N8bn_AVsXY7"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "With the loaded model we can now predict the labels of test set's texts and compare thos predicted labels with the one already in the dataset to understand the models performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y_logits = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_mask = batch[0].to(device), batch[1].to(device)\n",
        "        batch_y_logits = best_model(input_ids, attention_mask).logits\n",
        "        test_y_logits.append(batch_y_logits)\n",
        "\n",
        "test_y_logits = torch.cat(test_y_logits, dim=0)\n",
        "print(test_y_logits)"
      ],
      "metadata": {
        "id": "hO4pA3i2CUTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFBY_wgsg6wg"
      },
      "source": [
        "Now these \"logits\" have to be converted to (number) labels.\n",
        "\n",
        "Based on the selected ``problem_type``, the following code selects the correct decision function. The decision function converts the scores the model predicts into the actual decision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZD7XiARg6KS"
      },
      "outputs": [],
      "source": [
        "# In multi-label classification, every label for which the model predicts a\n",
        "# score above this value is said as being predicted\n",
        "multi_label_decision_threshold = 0\n",
        "\n",
        "decision_function = {\n",
        "    # select single label with highest score\n",
        "    'single_label_classification': lambda x: torch.argmax(x, dim=1),\n",
        "    # select all labels with score above the threshold\n",
        "    'multi_label_classification': lambda x: torch.where(\n",
        "        x > multi_label_decision_threshold, 1, 0)\n",
        "}[problem_type]\n",
        "\n",
        "test_y_pred = decision_function(test_y_logits).cpu()\n",
        "print(test_y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can finally compare how the predicted labels (`test_y_pred`) align with the labels that came along with the dataset (`test_y`). The scikit-learn library provides a nice report function to compare them."
      ],
      "metadata": {
        "id": "SP2I2CTWCuJt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXp0j0r5Tg4y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_y, test_y_pred, target_names=label2id.keys(), zero_division=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpBm7kAZoAOz"
      },
      "source": [
        "### Results\n",
        "\n",
        "The classification report shows us four metric results these are the precision,\n",
        "the recall, the f1-score, and the accuracy. Additionally, the report displays two different average aggregations, these are the macro avg, and the weighted average.\n",
        "\n",
        "The *precision* tells us \"When we predict a label, is it the correct label?\"\n",
        "\n",
        "The *recall* tells us \"How many instances of a class do we find?\"\n",
        "\n",
        "The *f1-score* is the harmonic mean of the *precision* and the *recall*.\n",
        "\n",
        "The *accuracy* tells us \"How many of our predictions are correct?\"\n",
        "\n",
        "The *macro avg* aggregates the *f1-score* per class it tells us \"How well do we classify, if all classes occur equally often?\"\n",
        "\n",
        "The *weighted avg* aggregates the *f1-score* weighted by class size it tells us \"How well do we classify the complete label set?\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Reading\n",
        "\n",
        "- [Unsupervised Cross-lingual Representation Learning at Scale](https://arxiv.org/pdf/1911.02116)\n",
        "- [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/pdf/1907.11692)\n",
        "- [CamemBERT: a Tasty French Language Model](https://arxiv.org/pdf/1911.03894)\n",
        "- [WECHSEL: Effective initialization of subword embeddings for cross-lingual transfer of monolingual language models](https://aclanthology.org/2022.naacl-main.293.pdf)\n",
        "- [Sharpness-Aware Minimization for Efficiently Improving Generalization](https://arxiv.org/pdf/2010.01412)"
      ],
      "metadata": {
        "id": "IR1ldehFV7xV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-G0nQF57ePk"
      },
      "source": [
        "## Contact Details\n",
        " For questions or feedback, contact Stephan Linzbach via [Stephan.Linzbach@gesis.org](mailto:Stephan.Linzbach@gesis.org)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "textclassification_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}